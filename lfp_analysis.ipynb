{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Instructions to run lfp_analysis.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lfp_analysis\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Convert the video files to mp4 format by passing the experiment directory\n",
    "\n",
    "Experiment directory should be the root directory that contains all experiment files.\n",
    "\n",
    "If needed, loop through the function below to convert the video files from .h264 to mp4 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"/Volumes/chaitra/reward_competition_extension/data\"\n",
    "lfp_analysis.convert_to_mp4(experiment_dir)\n",
    "\n",
    "# Loop through all the directories in the experiment directory\n",
    "for directory in os.listdir(experiment_dir):\n",
    "    if os.path.isdir(os.path.join(experiment_dir, directory)):\n",
    "        lfp_analysis.convert_to_mp4(os.path.join(experiment_dir, directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Input parameters to create LfpExperiment object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = \"/Volumes/chaitra/reward_competition_extension/data\"\n",
    "experiment_description = \"chaitra_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Input parameters to create LfpRecordingObject\n",
    "\n",
    "channel_map_path: Path to the channel mapping excel file\n",
    "\n",
    "events_path (video): Path to the events Excel file\n",
    "\n",
    "input_dir: Path to the directory containing the \\*.rec files\n",
    "\n",
    "sleap_path: Path to the directory containing the sleap files\n",
    "\n",
    "phy_path: Path to the directory containing the phy curation files. Should be in the format of phy_curation/experiment_session/phy/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_map_path = \"input/channel_mapping.xlsx\"\n",
    "events_path = \"input/events.xlsx\"\n",
    "\n",
    "#This list has to be in the same order as the files in the input directory\n",
    "list_subjects = [\"1.4_and_1.2\", \"2.1_and_2.2\", \"1.1_and_1.2\", \"2.1_and_2.4\"]\n",
    "#TODO: dictionary with key as .rec and values as subject\n",
    "\n",
    "input_dir = \"/Volumes/chaitra/reward_competition_extension/data/standard/2023_06_*/*.rec\"\n",
    "sleap_path = \"/Volumes/chaitra/reward_competition_extension/data/proc/sleap/\"\n",
    "output_path = \"/Volumes/chaitra/reward_competition_extension/data/outputs/\"\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "#tagging label excel values\n",
    "encoding_dict = {'Subj 1 blocking Subj 2': \"competitive\",\n",
    "    'Subj 2 Only': \"no_comp\",\n",
    "    'Subj 2 blocking Subj 1': \"competitive\",\n",
    "    'Subj 1 then Subj 2': \"competitive\",\n",
    "    'Subj 1 Only': \"no_comp\",\n",
    "    'Subj 2 then Subj 1': \"competitive\",\n",
    "    'Close Call': \"competitive\",\n",
    "    'After trial': \"no_comp\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(channel_map_path) or not os.path.exists(events_path):\n",
    "    raise Exception(\"Please provide the correct path for channel_map_path, events_path and labels_path\")\n",
    "\n",
    "if not os.path.exists(sleap_path):\n",
    "    raise Exception(\"Please provide the correct path for sleap_path\")\n",
    "\n",
    "#Check if input directory exists, wildcard is allowed\n",
    "if not glob.glob(input_dir):\n",
    "    raise Exception(\"Please provide the correct path for input_dir\")\n",
    "\n",
    "if len(list_subjects) == 0:\n",
    "    raise Exception(\"Provided list_subjects is empty\")\n",
    "\n",
    "#print input dir files\n",
    "num_rec = 0\n",
    "for file in glob.glob(input_dir):\n",
    "    if file.endswith(\".rec\"):\n",
    "        num_rec += 1\n",
    "        print(file + \"\\n\")\n",
    "\n",
    "if len(list_subjects) != num_rec:\n",
    "    raise Exception(\"Number of subjects in list_subjects is not equal to the number of files in the input directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Expr object\n",
    "my_expr = lfp_analysis.LfpExperiment(experiment=experiment_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "# Loop through input directory and create LFP objects for each session\n",
    "for file in glob.glob(input_dir):\n",
    "    lfp = lfp_analysis.LfpRecordingObject(path=file,\n",
    "                                           channel_map_path=channel_map_path,\n",
    "                                           sleap_path=sleap_path,\n",
    "                                           events_path=events_path,\n",
    "                                           encoding_dict=encoding_dict,\n",
    "                                           experiment_name=experiment_description,\n",
    "                                           output_path=output_path,\n",
    "                                           subject=list_subjects[counter],\n",
    "                                           time_window_step=0.5,\n",
    "                                           time_window_duration=1,\n",
    "                                           time_half_bandwidth_prod=2)\n",
    "    lfp.make_object()\n",
    "    my_expr.add_lfp_object(lfp_object=lfp, subject=lfp.subject)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the experiment object and call analysis functions\n",
    "for subject, lfp_obj in my_expr.list_of_lfp_objects.items():\n",
    "    # Must call make_spike_df before make_power_df\n",
    "    lfp_obj.make_spike_df()\n",
    "    lfp_obj.make_power_df()\n",
    "\n",
    "    # All other functions can be called in any order, but need to be called after make_spike_df and make_power_df\n",
    "    lfp_obj.make_phase_df()\n",
    "    lfp_obj.make_coherence_df()\n",
    "    lfp_obj.make_granger_df()\n",
    "    lfp_obj.make_filter_bands_df()\n",
    "\n",
    "    # Analysis functions for sleap data\n",
    "    lfp_obj.make_sleap_df()\n",
    "    lfp_obj.analyze_sleap(thorax_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the experiment object and add trial labels\n",
    "labels_path = \"input/labels.xlsx\"\n",
    "for subject, lfp_obj in my_expr.list_of_lfp_objects.items():\n",
    "    lfp_obj.add_labels(labels_path=labels_path)\n",
    "    lfp_obj.add_label_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_pickle(\"/Volumes/chaitra/reward_competition_extension/data/outputs/1.4_and_1.2/metadata.pkl\")\n",
    "print(metadata.columns)\n",
    "#session_dir is path w/o first half\n",
    "# TODO only need session_dir, original_file, subject, first_timestamps\n",
    "#data = first time stamp and increments by one till end of recording\n",
    "#data just save the len of np array (length recording)\n",
    "\n",
    "#ecu=false\n",
    "#you do not need first_item_data and last_item_data\n",
    "\n",
    "# rms traces as attribute (eg 5xN np array)\n",
    "\n",
    "#filter would be a method applied on the 3 (rms, zscored, raw)(filter or unfiltered) traces\n",
    "#default should be rms filtered\n",
    "#save raw and zscore as attribute\n",
    "#attribute = order of brain regions (get from channel mapping)\n",
    "\n",
    "#plot zscore with threshold --> line or scatter\n",
    "\n",
    "#power timestamps and frequencies (coherence) could be attributes\n",
    "\n",
    "#MAD get rid of (array of 5x1 ) and they are just one number (attribute)\n",
    "\n",
    "#power main attribute would be rms_filtered, could be an input param,\n",
    "power = pd.read_pickle(\"/Volumes/chaitra/reward_competition_extension/data/outputs/1.4_and_1.2/power_df.pkl\")\n",
    "#print(power.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere = pd.read_pickle(\"/Volumes/chaitra/reward_competition_extension/data/outputs/1.4_and_1.2/coherence_df.pkl\")\n",
    "print(cohere.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gran = pd.read_pickle(\"/Volumes/chaitra/reward_competition_extension/data/outputs/1.4_and_1.2/granger_df.pkl\")\n",
    "print(gran.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
